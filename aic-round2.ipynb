{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "labels_csv_path = 'Training.csv'\n",
    "df = pd.read_csv(labels_csv_path)\n",
    "\n",
    "image_files = df['Image'].values\n",
    "labels = df['Label'].values\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_files, val_files, train_labels, val_labels = train_test_split(image_files, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, directory, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.label_mapping = {\n",
    "            'Normal': 0,\n",
    "            'Mitosis': 1\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_paths[idx]\n",
    "        label_text = self.labels[idx]\n",
    "        label = self.label_mapping[label_text]\n",
    "        label_tensor = torch.tensor(label, dtype=torch.float32)\n",
    "        \n",
    "        img_path = f\"{self.directory}/{img_name}\"\n",
    "        image = Image.open(img_path).convert('RGB')  # Ensure image is RGB\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label_tensor\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CustomDataset(train_files, train_labels, 'Training Images', transform=transform)\n",
    "val_dataset = CustomDataset(val_files, val_labels, 'Training Images', transform=transform)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, image_paths, directory, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_paths[idx]\n",
    "        img_path = f\"{self.directory}/{img_name}\"\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "test_df = pd.read_csv('Testing.csv')\n",
    "test_image_files = test_df['Image'].values\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_dataset = TestDataset(test_image_files, 'Testing Image', transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('Training.csv')\n",
    "\n",
    "df['Label'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribution of Labels in Training.csv')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 9.7874, Train Acc: 0.4808, Train F1: 0.5263, Val Loss: 2.3970, Val Acc: 0.3571, Val F1: 0.0000\n",
      "Epoch 2/50, Train Loss: 1.9953, Train Acc: 0.7308, Train F1: 0.7812, Val Loss: 2.4437, Val Acc: 0.3571, Val F1: 0.0000\n",
      "Epoch 3/50, Train Loss: 2.8428, Train Acc: 0.7500, Train F1: 0.8060, Val Loss: 2.4792, Val Acc: 0.5000, Val F1: 0.4615\n",
      "Epoch 4/50, Train Loss: 1.3122, Train Acc: 0.7115, Train F1: 0.7273, Val Loss: 0.5562, Val Acc: 0.5714, Val F1: 0.6667\n",
      "Epoch 5/50, Train Loss: 1.2808, Train Acc: 0.6923, Train F1: 0.7333, Val Loss: 2.1213, Val Acc: 0.7143, Val F1: 0.8000\n",
      "Epoch 6/50, Train Loss: 1.6485, Train Acc: 0.7885, Train F1: 0.8406, Val Loss: 3.0611, Val Acc: 0.6429, Val F1: 0.7619\n",
      "Epoch 7/50, Train Loss: 0.8684, Train Acc: 0.8077, Train F1: 0.8214, Val Loss: 1.6238, Val Acc: 0.5714, Val F1: 0.6667\n",
      "Epoch 8/50, Train Loss: 0.6335, Train Acc: 0.8462, Train F1: 0.8750, Val Loss: 0.6017, Val Acc: 0.6429, Val F1: 0.7619\n",
      "Epoch 9/50, Train Loss: 0.9252, Train Acc: 0.8077, Train F1: 0.8571, Val Loss: 0.2011, Val Acc: 0.6429, Val F1: 0.6154\n",
      "Epoch 10/50, Train Loss: 1.7265, Train Acc: 0.6154, Train F1: 0.6000, Val Loss: 1.4570, Val Acc: 0.5714, Val F1: 0.6667\n",
      "Epoch 11/50, Train Loss: 0.5965, Train Acc: 0.8462, Train F1: 0.8788, Val Loss: 0.4248, Val Acc: 0.5714, Val F1: 0.6667\n",
      "Epoch 12/50, Train Loss: 1.4200, Train Acc: 0.6538, Train F1: 0.6667, Val Loss: 1.7290, Val Acc: 0.5714, Val F1: 0.6667\n",
      "Epoch 13/50, Train Loss: 1.2361, Train Acc: 0.6538, Train F1: 0.6786, Val Loss: 1.3145, Val Acc: 0.5714, Val F1: 0.6667\n",
      "Epoch 14/50, Train Loss: 0.6888, Train Acc: 0.8846, Train F1: 0.9091, Val Loss: 1.0065, Val Acc: 0.5714, Val F1: 0.7000\n",
      "Epoch 15/50, Train Loss: 0.6186, Train Acc: 0.8269, Train F1: 0.8525, Val Loss: 0.9351, Val Acc: 0.5000, Val F1: 0.5882\n",
      "Epoch 16/50, Train Loss: 0.2523, Train Acc: 0.8654, Train F1: 0.8772, Val Loss: 0.0257, Val Acc: 0.5000, Val F1: 0.6316\n",
      "Epoch 17/50, Train Loss: 1.2342, Train Acc: 0.7885, Train F1: 0.8451, Val Loss: 0.9446, Val Acc: 0.7143, Val F1: 0.7778\n",
      "Epoch 18/50, Train Loss: 0.4129, Train Acc: 0.8269, Train F1: 0.8364, Val Loss: 0.6368, Val Acc: 0.4286, Val F1: 0.5000\n",
      "Epoch 19/50, Train Loss: 0.8617, Train Acc: 0.7885, Train F1: 0.8136, Val Loss: 1.0383, Val Acc: 0.6429, Val F1: 0.7368\n",
      "Epoch 20/50, Train Loss: 1.1309, Train Acc: 0.8077, Train F1: 0.8571, Val Loss: 2.1228, Val Acc: 0.3571, Val F1: 0.4000\n",
      "Epoch 21/50, Train Loss: 1.7256, Train Acc: 0.6538, Train F1: 0.5909, Val Loss: 2.5823, Val Acc: 0.4286, Val F1: 0.5000\n",
      "Epoch 22/50, Train Loss: 0.6781, Train Acc: 0.8462, Train F1: 0.8824, Val Loss: 0.9938, Val Acc: 0.6429, Val F1: 0.7368\n",
      "Epoch 23/50, Train Loss: 2.6805, Train Acc: 0.7692, Train F1: 0.8333, Val Loss: 5.8208, Val Acc: 0.5714, Val F1: 0.6667\n",
      "Epoch 24/50, Train Loss: 0.4122, Train Acc: 0.9423, Train F1: 0.9508, Val Loss: 0.0577, Val Acc: 0.3571, Val F1: 0.3077\n",
      "Epoch 25/50, Train Loss: 1.6926, Train Acc: 0.6923, Train F1: 0.6522, Val Loss: 0.5865, Val Acc: 0.5714, Val F1: 0.6667\n",
      "Epoch 26/50, Train Loss: 2.0516, Train Acc: 0.8269, Train F1: 0.8657, Val Loss: 5.7252, Val Acc: 0.5714, Val F1: 0.6667\n",
      "Epoch 27/50, Train Loss: 0.3708, Train Acc: 0.9423, Train F1: 0.9524, Val Loss: 0.0482, Val Acc: 0.5000, Val F1: 0.5882\n",
      "Epoch 28/50, Train Loss: 0.7994, Train Acc: 0.9231, Train F1: 0.9310, Val Loss: 2.1752, Val Acc: 0.4286, Val F1: 0.5000\n",
      "Epoch 29/50, Train Loss: 0.2495, Train Acc: 0.9038, Train F1: 0.9123, Val Loss: 0.0266, Val Acc: 0.6429, Val F1: 0.7368\n",
      "Epoch 30/50, Train Loss: 0.3592, Train Acc: 0.8846, Train F1: 0.9091, Val Loss: 0.5802, Val Acc: 0.7143, Val F1: 0.8000\n",
      "Epoch 31/50, Train Loss: 0.1875, Train Acc: 0.9423, Train F1: 0.9524, Val Loss: 0.0184, Val Acc: 0.6429, Val F1: 0.7368\n",
      "Epoch 32/50, Train Loss: 0.0738, Train Acc: 0.9423, Train F1: 0.9508, Val Loss: 0.0277, Val Acc: 0.6429, Val F1: 0.7059\n",
      "Epoch 33/50, Train Loss: 0.3919, Train Acc: 0.8846, Train F1: 0.8889, Val Loss: 0.8649, Val Acc: 0.7143, Val F1: 0.7778\n",
      "Epoch 34/50, Train Loss: 0.2944, Train Acc: 0.8846, Train F1: 0.9032, Val Loss: 0.5505, Val Acc: 0.7143, Val F1: 0.8000\n",
      "Epoch 35/50, Train Loss: 0.3719, Train Acc: 0.8462, Train F1: 0.8824, Val Loss: 0.5844, Val Acc: 0.5000, Val F1: 0.5333\n",
      "Epoch 36/50, Train Loss: 0.5184, Train Acc: 0.7885, Train F1: 0.7925, Val Loss: 0.9928, Val Acc: 0.4286, Val F1: 0.4286\n",
      "Epoch 37/50, Train Loss: 0.0787, Train Acc: 0.9615, Train F1: 0.9655, Val Loss: 0.0857, Val Acc: 0.5714, Val F1: 0.6250\n",
      "Epoch 38/50, Train Loss: 0.6237, Train Acc: 0.8654, Train F1: 0.8955, Val Loss: 1.2534, Val Acc: 0.5714, Val F1: 0.6667\n",
      "Epoch 39/50, Train Loss: 0.2068, Train Acc: 0.9423, Train F1: 0.9524, Val Loss: 0.0136, Val Acc: 0.5000, Val F1: 0.5333\n",
      "Epoch 40/50, Train Loss: 0.5259, Train Acc: 0.8846, Train F1: 0.8929, Val Loss: 1.3223, Val Acc: 0.5000, Val F1: 0.5333\n",
      "Epoch 41/50, Train Loss: 0.3641, Train Acc: 0.9038, Train F1: 0.9153, Val Loss: 0.1784, Val Acc: 0.5714, Val F1: 0.6667\n",
      "Epoch 42/50, Train Loss: 0.2493, Train Acc: 0.9038, Train F1: 0.9231, Val Loss: 0.0621, Val Acc: 0.5714, Val F1: 0.6667\n",
      "Epoch 43/50, Train Loss: 0.1116, Train Acc: 0.9423, Train F1: 0.9524, Val Loss: 0.0175, Val Acc: 0.5714, Val F1: 0.6667\n",
      "Epoch 44/50, Train Loss: 0.1213, Train Acc: 0.9423, Train F1: 0.9474, Val Loss: 0.2047, Val Acc: 0.6429, Val F1: 0.7059\n",
      "Epoch 45/50, Train Loss: 0.0976, Train Acc: 0.9615, Train F1: 0.9667, Val Loss: 0.1043, Val Acc: 0.6429, Val F1: 0.7368\n",
      "Epoch 46/50, Train Loss: 0.1767, Train Acc: 0.9615, Train F1: 0.9677, Val Loss: 0.4643, Val Acc: 0.6429, Val F1: 0.7368\n",
      "Epoch 47/50, Train Loss: 0.1478, Train Acc: 0.9423, Train F1: 0.9524, Val Loss: 0.0704, Val Acc: 0.6429, Val F1: 0.7059\n",
      "Epoch 48/50, Train Loss: 0.1161, Train Acc: 0.9615, Train F1: 0.9655, Val Loss: 0.0104, Val Acc: 0.6429, Val F1: 0.7059\n",
      "Epoch 49/50, Train Loss: 0.1593, Train Acc: 0.9615, Train F1: 0.9655, Val Loss: 0.2526, Val Acc: 0.5714, Val F1: 0.6667\n",
      "Epoch 50/50, Train Loss: 0.2125, Train Acc: 0.9231, Train F1: 0.9375, Val Loss: 0.0113, Val Acc: 0.6429, Val F1: 0.7059\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Define transforms with augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = CustomDataset(train_files, train_labels, 'Training Image', transform=transform)\n",
    "val_dataset = CustomDataset(val_files, val_labels, 'Training Image', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=20, shuffle=False)\n",
    "\n",
    "# Model architecture\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 18 * 18, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming binary classification\n",
    "labels_unique = np.unique(train_labels)\n",
    "class_weights = compute_class_weight('balanced', classes=labels_unique, y=train_labels)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights_tensor[1])\n",
    "\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_preds, train_targets = [], []\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "            preds = torch.sigmoid(outputs).data > 0.5\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(train_targets, train_preds)\n",
    "        train_f1 = f1_score(train_targets, train_preds)\n",
    "\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        val_preds, val_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                val_losses.append(loss.item())\n",
    "                \n",
    "                preds = torch.sigmoid(outputs).data > 0.5\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_targets.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_acc = accuracy_score(val_targets, val_preds)\n",
    "        val_f1 = f1_score(val_targets, val_preds)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {np.mean(train_losses):.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}, Val Loss: {np.mean(val_losses):.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}')\n",
    "\n",
    "model1 = train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test_Predictions_1 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = (probs > 0.5).int()\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "    return np.array(predictions).flatten()\n",
    "\n",
    "test_predictions = predict(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping_inverse = {0: 'Normal', 1: 'Mitosis'}\n",
    "textual_predictions = [label_mapping_inverse[pred] for pred in test_predictions]\n",
    "test_df['Label'] = textual_predictions\n",
    "test_df.to_csv('Test_Predictions_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with enhancements\n",
    "- early stopping\n",
    "- more augmentation\n",
    "- learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fatima Azfar\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current learning rate: 0.001\n",
      "Epoch 1/20, Train Loss: 8.2311, Train Acc: 0.5962, Train F1: 0.6957, Val Loss: 2.0970, Val Acc: 0.4286, Val F1: 0.2000\n",
      "Current learning rate: 0.001\n",
      "Epoch 2/20, Train Loss: 1.5852, Train Acc: 0.5769, Train F1: 0.6562, Val Loss: 1.8058, Val Acc: 0.5000, Val F1: 0.3636\n",
      "Current learning rate: 0.001\n",
      "Epoch 3/20, Train Loss: 0.9130, Train Acc: 0.7115, Train F1: 0.7368, Val Loss: 0.9175, Val Acc: 0.6429, Val F1: 0.7619\n",
      "Current learning rate: 0.001\n",
      "Epoch 4/20, Train Loss: 2.8212, Train Acc: 0.6346, Train F1: 0.7595, Val Loss: 4.6052, Val Acc: 0.3571, Val F1: 0.0000\n",
      "Current learning rate: 0.001\n",
      "Epoch 5/20, Train Loss: 1.9443, Train Acc: 0.5192, Train F1: 0.3902, Val Loss: 0.9114, Val Acc: 0.2857, Val F1: 0.1667\n",
      "Current learning rate: 0.001\n",
      "Epoch 6/20, Train Loss: 1.8803, Train Acc: 0.6154, Train F1: 0.7143, Val Loss: 1.9252, Val Acc: 0.5714, Val F1: 0.6250\n",
      "Current learning rate: 0.001\n",
      "Epoch 7/20, Train Loss: 1.2429, Train Acc: 0.7115, Train F1: 0.7368, Val Loss: 2.0085, Val Acc: 0.7143, Val F1: 0.7500\n",
      "Current learning rate: 0.001\n",
      "Epoch 8/20, Train Loss: 0.8534, Train Acc: 0.7500, Train F1: 0.7937, Val Loss: 0.0624, Val Acc: 0.7143, Val F1: 0.8000\n",
      "Current learning rate: 0.001\n",
      "Epoch 9/20, Train Loss: 1.4135, Train Acc: 0.7115, Train F1: 0.7826, Val Loss: 1.4854, Val Acc: 0.6429, Val F1: 0.7059\n",
      "Current learning rate: 0.001\n",
      "Epoch 10/20, Train Loss: 0.8431, Train Acc: 0.6923, Train F1: 0.7143, Val Loss: 0.8228, Val Acc: 0.5000, Val F1: 0.5882\n",
      "Current learning rate: 0.001\n",
      "Epoch 11/20, Train Loss: 0.5965, Train Acc: 0.7500, Train F1: 0.7937, Val Loss: 0.3588, Val Acc: 0.5714, Val F1: 0.7000\n",
      "Current learning rate: 0.0005\n",
      "Epoch 12/20, Train Loss: 0.8044, Train Acc: 0.7692, Train F1: 0.8235, Val Loss: 0.5234, Val Acc: 0.5000, Val F1: 0.5882\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Define transforms with augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = CustomDataset(train_files, train_labels, 'Training Image', transform=transform)\n",
    "val_dataset = CustomDataset(val_files, val_labels, 'Training Image', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=20, shuffle=False)\n",
    "\n",
    "# Model architecture\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 18 * 18, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming binary classification\n",
    "labels_unique = np.unique(train_labels)\n",
    "class_weights = compute_class_weight('balanced', classes=labels_unique, y=train_labels)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights_tensor[1])\n",
    "\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 5  # Number of epochs to wait for improvement before stopping\n",
    "    patience_counter = 0  # Counter for patience\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5, min_lr=1e-6, verbose=True)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_preds, train_targets = [], []\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "            preds = torch.sigmoid(outputs).data > 0.5\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(train_targets, train_preds)\n",
    "        train_f1 = f1_score(train_targets, train_preds)\n",
    "\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        val_preds, val_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                val_losses.append(loss.item())\n",
    "                \n",
    "                preds = torch.sigmoid(outputs).data > 0.5\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_targets.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_acc = accuracy_score(val_targets, val_preds)\n",
    "        val_f1 = f1_score(val_targets, val_preds)\n",
    "        \n",
    "        # Early Stopping Check\n",
    "        if np.mean(val_losses) < best_val_loss:\n",
    "            best_val_loss = np.mean(val_losses)\n",
    "            patience_counter = 0  # Reset counter\n",
    "            # Save the best model\n",
    "            torch.save(model.state_dict(), \"best_model3.pth\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "        \n",
    "        scheduler.step(np.mean(val_losses))\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        print(f'Current learning rate: {current_lr}')\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {np.mean(train_losses):.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}, Val Loss: {np.mean(val_losses):.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}')\n",
    "\n",
    "model3 = train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test_Predictions_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = (probs > 0.5).int()\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "    return np.array(predictions).flatten()\n",
    "\n",
    "test_predictions = predict(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping_inverse = {0: 'Normal', 1: 'Mitosis'}\n",
    "textual_predictions = [label_mapping_inverse[pred] for pred in test_predictions]\n",
    "test_df['Label'] = textual_predictions\n",
    "test_df.to_csv('Test_Predictions_6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fatima Azfar\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current learning rate: 0.001\n",
      "Epoch 1/20, Train Loss: 8.2311, Train Acc: 0.5962, Train F1: 0.6957, Val Loss: 2.0970, Val Acc: 0.4286, Val F1: 0.2000\n",
      "Current learning rate: 0.001\n",
      "Epoch 2/20, Train Loss: 1.5852, Train Acc: 0.5769, Train F1: 0.6562, Val Loss: 1.8058, Val Acc: 0.5000, Val F1: 0.3636\n",
      "Current learning rate: 0.001\n",
      "Epoch 3/20, Train Loss: 0.9130, Train Acc: 0.7115, Train F1: 0.7368, Val Loss: 0.9175, Val Acc: 0.6429, Val F1: 0.7619\n",
      "Current learning rate: 0.001\n",
      "Epoch 4/20, Train Loss: 2.8212, Train Acc: 0.6346, Train F1: 0.7595, Val Loss: 4.6052, Val Acc: 0.3571, Val F1: 0.0000\n",
      "Current learning rate: 0.001\n",
      "Epoch 5/20, Train Loss: 1.9443, Train Acc: 0.5192, Train F1: 0.3902, Val Loss: 0.9114, Val Acc: 0.2857, Val F1: 0.1667\n",
      "Current learning rate: 0.001\n",
      "Epoch 6/20, Train Loss: 1.8803, Train Acc: 0.6154, Train F1: 0.7143, Val Loss: 1.9252, Val Acc: 0.5714, Val F1: 0.6250\n",
      "Current learning rate: 0.001\n",
      "Epoch 7/20, Train Loss: 1.2429, Train Acc: 0.7115, Train F1: 0.7368, Val Loss: 2.0085, Val Acc: 0.7143, Val F1: 0.7500\n",
      "Current learning rate: 0.001\n",
      "Epoch 8/20, Train Loss: 0.8534, Train Acc: 0.7500, Train F1: 0.7937, Val Loss: 0.0624, Val Acc: 0.7143, Val F1: 0.8000\n",
      "Current learning rate: 0.001\n",
      "Epoch 9/20, Train Loss: 1.4135, Train Acc: 0.7115, Train F1: 0.7826, Val Loss: 1.4854, Val Acc: 0.6429, Val F1: 0.7059\n",
      "Current learning rate: 0.001\n",
      "Epoch 10/20, Train Loss: 0.8431, Train Acc: 0.6923, Train F1: 0.7143, Val Loss: 0.8228, Val Acc: 0.5000, Val F1: 0.5882\n",
      "Current learning rate: 0.001\n",
      "Epoch 11/20, Train Loss: 0.5965, Train Acc: 0.7500, Train F1: 0.7937, Val Loss: 0.3588, Val Acc: 0.5714, Val F1: 0.7000\n",
      "Current learning rate: 0.0005\n",
      "Epoch 12/20, Train Loss: 0.8044, Train Acc: 0.7692, Train F1: 0.8235, Val Loss: 0.5234, Val Acc: 0.5000, Val F1: 0.5882\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Define transforms with augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = CustomDataset(train_files, train_labels, 'Training Image', transform=transform)\n",
    "val_dataset = CustomDataset(val_files, val_labels, 'Training Image', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=20, shuffle=False)\n",
    "\n",
    "# Model architecture\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 18 * 18, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming binary classification\n",
    "labels_unique = np.unique(train_labels)\n",
    "class_weights = compute_class_weight('balanced', classes=labels_unique, y=train_labels)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights_tensor[1])\n",
    "\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 5  # Number of epochs to wait for improvement before stopping\n",
    "    patience_counter = 0  # Counter for patience\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5, min_lr=1e-6, verbose=True)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_preds, train_targets = [], []\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "            preds = torch.sigmoid(outputs).data > 0.5\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(train_targets, train_preds)\n",
    "        train_f1 = f1_score(train_targets, train_preds)\n",
    "\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        val_preds, val_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                val_losses.append(loss.item())\n",
    "                \n",
    "                preds = torch.sigmoid(outputs).data > 0.5\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_targets.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_acc = accuracy_score(val_targets, val_preds)\n",
    "        val_f1 = f1_score(val_targets, val_preds)\n",
    "        \n",
    "        # Early Stopping Check\n",
    "        if np.mean(val_losses) < best_val_loss:\n",
    "            best_val_loss = np.mean(val_losses)\n",
    "            patience_counter = 0  # Reset counter\n",
    "            # Save the best model\n",
    "            torch.save(model.state_dict(), \"best_model3.pth\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "        \n",
    "        scheduler.step(np.mean(val_losses))\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        print(f'Current learning rate: {current_lr}')\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {np.mean(train_losses):.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}, Val Loss: {np.mean(val_losses):.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}')\n",
    "\n",
    "model3 = train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(train_files, train_labels, 'Training Image', transform=transform)\n",
    "val_dataset = CustomDataset(val_files, val_labels, 'Training Image', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_to_array(loader):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for image_batch, label_batch in loader:\n",
    "        for i in range(len(image_batch)):\n",
    "            # Flatten images or extract features here\n",
    "            image = image_batch[i].numpy().flatten()\n",
    "            images.append(image)\n",
    "            labels.append(label_batch[i].item())\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_train, y_train = dataloader_to_array(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Convert arrays back to tensors\n",
    "X_smote_tensor = torch.tensor(X_smote, dtype=torch.float).reshape((-1, 3, 224, 224))\n",
    "y_smote_tensor = torch.tensor(y_smote, dtype=torch.long)\n",
    "\n",
    "# Create a new TensorDataset and DataLoader\n",
    "smote_dataset = TensorDataset(X_smote_tensor, y_smote_tensor)\n",
    "train_loader = DataLoader(smote_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTForBinaryClassification(nn.Module):\n",
    "    def __init__(self, num_classes=1, pretrained=True):\n",
    "        super(ViTForBinaryClassification, self).__init__()\n",
    "        self.model = timm.create_model('vit_base_patch16_224', pretrained=pretrained)\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = ViTForBinaryClassification().to('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_unique = np.unique(train_labels)\n",
    "class_weights = compute_class_weight('balanced', classes=labels_unique, y=train_labels)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights_tensor[1])\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.1946452856063843, Train Acc: 0.6000, Train F1: 0.6000\n",
      "Validation Acc: 0.6429, Validation F1: 0.7826\n",
      "Epoch 2, Train Loss: 1.202429622411728, Train Acc: 0.5667, Train F1: 0.5938\n",
      "Validation Acc: 0.3571, Validation F1: 0.0000\n",
      "Epoch 3, Train Loss: 0.7471255362033844, Train Acc: 0.5000, Train F1: 0.4828\n",
      "Validation Acc: 0.5000, Validation F1: 0.6667\n",
      "Epoch 4, Train Loss: 0.7025513052940369, Train Acc: 0.6500, Train F1: 0.6667\n",
      "Validation Acc: 0.5000, Validation F1: 0.3636\n",
      "Epoch 5, Train Loss: 0.6384152770042419, Train Acc: 0.6833, Train F1: 0.6780\n",
      "Validation Acc: 0.6429, Validation F1: 0.7619\n",
      "Epoch 6, Train Loss: 0.6460458636283875, Train Acc: 0.7000, Train F1: 0.7692\n",
      "Validation Acc: 0.5000, Validation F1: 0.3636\n",
      "Epoch 7, Train Loss: 0.6178788244724274, Train Acc: 0.7000, Train F1: 0.6667\n",
      "Validation Acc: 0.5714, Validation F1: 0.6667\n",
      "Epoch 8, Train Loss: 0.5743424892425537, Train Acc: 0.7167, Train F1: 0.7733\n",
      "Validation Acc: 0.3571, Validation F1: 0.4000\n",
      "Epoch 9, Train Loss: 0.6008415520191193, Train Acc: 0.6500, Train F1: 0.6557\n",
      "Validation Acc: 0.4286, Validation F1: 0.4286\n",
      "Epoch 10, Train Loss: 0.560641348361969, Train Acc: 0.7333, Train F1: 0.7714\n",
      "Validation Acc: 0.5000, Validation F1: 0.5882\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, val_loader, epochs=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        total_loss = 0\n",
    "        train_preds, train_targets = [], []  # Initialize lists to store training predictions and targets\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Convert outputs to probabilities and then to binary predictions\n",
    "            preds = torch.sigmoid(outputs).data > 0.5\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Calculate and print training accuracy and F1 score\n",
    "        train_acc = accuracy_score(train_targets, np.round(train_preds))\n",
    "        train_f1 = f1_score(train_targets, np.round(train_preds))\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {total_loss / len(train_loader)}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}\")\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        val_preds, val_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = torch.sigmoid(model(images))\n",
    "                preds = (outputs > 0.5).int()\n",
    "                val_preds.extend(preds.view(-1).cpu().numpy())\n",
    "                val_targets.extend(labels.cpu().numpy())\n",
    "            \n",
    "            val_acc = accuracy_score(val_targets, val_preds)\n",
    "            val_f1 = f1_score(val_targets, val_preds)\n",
    "            print(f\"Validation Acc: {val_acc:.4f}, Validation F1: {val_f1:.4f}\")\n",
    "\n",
    "model2 = train_model(model, criterion, optimizer, train_loader, val_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test_Predictions_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('Testing.csv')\n",
    "test_image_files = test_df['Image'].values\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_dataset = TestDataset(test_image_files, 'Testing Image', transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=20, shuffle=False)\n",
    "\n",
    "test_predictions = predict(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping_inverse = {0: 'Normal', 1: 'Mitosis'}\n",
    "textual_predictions = [label_mapping_inverse[pred] for pred in test_predictions]\n",
    "test_df['Label'] = textual_predictions\n",
    "test_df.to_csv('Test_Predictions_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Transformer with Enhancements\n",
    "- added more augmentation techniques to counter overfitting\n",
    "- added learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0), ratio=(0.75, 1.33)),\n",
    "    transforms.RandomAdjustSharpness(2, p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(train_files, train_labels, 'Training Image', transform=transform)\n",
    "val_dataset = CustomDataset(val_files, val_labels, 'Training Image', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_to_array(loader):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for image_batch, label_batch in loader:\n",
    "        for i in range(len(image_batch)):\n",
    "            # Flatten images or extract features here\n",
    "            image = image_batch[i].numpy().flatten()\n",
    "            images.append(image)\n",
    "            labels.append(label_batch[i].item())\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_train, y_train = dataloader_to_array(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Convert arrays back to tensors\n",
    "X_smote_tensor = torch.tensor(X_smote, dtype=torch.float).reshape((-1, 3, 224, 224))\n",
    "y_smote_tensor = torch.tensor(y_smote, dtype=torch.long)\n",
    "\n",
    "# Create a new TensorDataset and DataLoader\n",
    "smote_dataset = TensorDataset(X_smote_tensor, y_smote_tensor)\n",
    "train_loader = DataLoader(smote_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTForBinaryClassification(nn.Module):\n",
    "    def __init__(self, num_classes=1, pretrained=True):\n",
    "        super(ViTForBinaryClassification, self).__init__()\n",
    "        self.model = timm.create_model('vit_base_patch16_224', pretrained=pretrained)\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = ViTForBinaryClassification().to('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_unique = np.unique(train_labels)\n",
    "class_weights = compute_class_weight('balanced', classes=labels_unique, y=train_labels)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights_tensor[1])\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.9885109066963196, Train Acc: 0.4667, Train F1: 0.4483\n",
      "Validation Acc: 0.5000, Validation F1: 0.6667\n",
      "Epoch 2, Train Loss: 0.9840219914913177, Train Acc: 0.5167, Train F1: 0.5246\n",
      "Validation Acc: 0.6429, Validation F1: 0.7368\n",
      "Epoch 3, Train Loss: 0.7323697209358215, Train Acc: 0.5833, Train F1: 0.7059\n",
      "Validation Acc: 0.6429, Validation F1: 0.7826\n",
      "Epoch 4, Train Loss: 0.6750957071781158, Train Acc: 0.6167, Train F1: 0.7229\n",
      "Validation Acc: 0.3571, Validation F1: 0.0000\n",
      "Epoch 5, Train Loss: 0.7038516104221344, Train Acc: 0.6500, Train F1: 0.4878\n",
      "Validation Acc: 0.5714, Validation F1: 0.6667\n",
      "Epoch 6, Train Loss: 0.5774530470371246, Train Acc: 0.7500, Train F1: 0.8000\n",
      "Validation Acc: 0.5714, Validation F1: 0.6250\n",
      "Epoch 7, Train Loss: 0.45825594663619995, Train Acc: 0.8833, Train F1: 0.8923\n",
      "Validation Acc: 0.7143, Validation F1: 0.7143\n",
      "Epoch 8, Train Loss: 0.4000968039035797, Train Acc: 0.8333, Train F1: 0.8214\n",
      "Validation Acc: 0.4286, Validation F1: 0.5000\n",
      "Epoch 9, Train Loss: 0.34576669335365295, Train Acc: 0.9167, Train F1: 0.9180\n",
      "Validation Acc: 0.6429, Validation F1: 0.7059\n",
      "Epoch 10, Train Loss: 0.3162180185317993, Train Acc: 0.9167, Train F1: 0.9206\n",
      "Validation Acc: 0.5714, Validation F1: 0.6250\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, val_loader, epochs=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        total_loss = 0\n",
    "        train_preds, train_targets = [], []  # Initialize lists to store training predictions and targets\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Convert outputs to probabilities and then to binary predictions\n",
    "            preds = torch.sigmoid(outputs).data > 0.5\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Calculate and print training accuracy and F1 score\n",
    "        train_acc = accuracy_score(train_targets, np.round(train_preds))\n",
    "        train_f1 = f1_score(train_targets, np.round(train_preds))\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {total_loss / len(train_loader)}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}\")\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        val_preds, val_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = torch.sigmoid(model(images))\n",
    "                preds = (outputs > 0.5).int()\n",
    "                val_preds.extend(preds.view(-1).cpu().numpy())\n",
    "                val_targets.extend(labels.cpu().numpy())\n",
    "            \n",
    "            val_acc = accuracy_score(val_targets, val_preds)\n",
    "            val_f1 = f1_score(val_targets, val_preds)\n",
    "            print(f\"Validation Acc: {val_acc:.4f}, Validation F1: {val_f1:.4f}\")\n",
    "\n",
    "model2 = train_model(model, criterion, optimizer, train_loader, val_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test_Predictions_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('Testing.csv')\n",
    "test_image_files = test_df['Image'].values\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_dataset = TestDataset(test_image_files, 'Testing Image', transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=20, shuffle=False)\n",
    "\n",
    "test_predictions = predict(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping_inverse = {0: 'Normal', 1: 'Mitosis'}\n",
    "textual_predictions = [label_mapping_inverse[pred] for pred in test_predictions]\n",
    "test_df['Label'] = textual_predictions\n",
    "test_df.to_csv('Test_Predictions_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Transformer with Enhancements\n",
    "- added more augmentation techniques to counter overfitting\n",
    "- adjusted the scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0), ratio=(0.75, 1.33)),\n",
    "    transforms.RandomAdjustSharpness(2, p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(train_files, train_labels, 'Training Image', transform=transform)\n",
    "val_dataset = CustomDataset(val_files, val_labels, 'Training Image', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_to_array(loader):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for image_batch, label_batch in loader:\n",
    "        for i in range(len(image_batch)):\n",
    "            # Flatten images or extract features here\n",
    "            image = image_batch[i].numpy().flatten()\n",
    "            images.append(image)\n",
    "            labels.append(label_batch[i].item())\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "X_train, y_train = dataloader_to_array(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Convert arrays back to tensors\n",
    "X_smote_tensor = torch.tensor(X_smote, dtype=torch.float).reshape((-1, 3, 224, 224))\n",
    "y_smote_tensor = torch.tensor(y_smote, dtype=torch.long)\n",
    "\n",
    "# Create a new TensorDataset and DataLoader\n",
    "smote_dataset = TensorDataset(X_smote_tensor, y_smote_tensor)\n",
    "train_loader = DataLoader(smote_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTForBinaryClassification(nn.Module):\n",
    "    def __init__(self, num_classes=1, pretrained=True):\n",
    "        super(ViTForBinaryClassification, self).__init__()\n",
    "        self.model = timm.create_model('vit_base_patch16_224', pretrained=pretrained)\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = ViTForBinaryClassification().to('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_unique = np.unique(train_labels)\n",
    "class_weights = compute_class_weight('balanced', classes=labels_unique, y=train_labels)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights_tensor[1])\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.256094366312027, Train Acc: 0.5833, Train F1: 0.6753\n",
      "Validation Acc: 0.3571, Validation F1: 0.0000\n",
      "Epoch 2, Train Loss: 1.0873625576496124, Train Acc: 0.6000, Train F1: 0.3684\n",
      "Validation Acc: 0.6429, Validation F1: 0.7826\n",
      "Epoch 3, Train Loss: 0.7187078297138214, Train Acc: 0.5833, Train F1: 0.7059\n",
      "Validation Acc: 0.2857, Validation F1: 0.0000\n",
      "Epoch 4, Train Loss: 0.6722207963466644, Train Acc: 0.6333, Train F1: 0.5000\n",
      "Validation Acc: 0.6429, Validation F1: 0.7368\n",
      "Epoch 5, Train Loss: 0.5516555309295654, Train Acc: 0.7667, Train F1: 0.7879\n",
      "Validation Acc: 0.4286, Validation F1: 0.5556\n",
      "Epoch 6, Train Loss: 0.4896591156721115, Train Acc: 0.7833, Train F1: 0.8000\n",
      "Validation Acc: 0.4286, Validation F1: 0.4286\n",
      "Epoch 7, Train Loss: 0.45933590829372406, Train Acc: 0.8000, Train F1: 0.7857\n",
      "Validation Acc: 0.6429, Validation F1: 0.7368\n",
      "Epoch 8, Train Loss: 0.3212045282125473, Train Acc: 0.8833, Train F1: 0.8889\n",
      "Validation Acc: 0.4286, Validation F1: 0.6000\n",
      "Epoch 9, Train Loss: 0.31889405846595764, Train Acc: 0.8833, Train F1: 0.8889\n",
      "Validation Acc: 0.7143, Validation F1: 0.8000\n",
      "Epoch 10, Train Loss: 0.299641951918602, Train Acc: 0.8833, Train F1: 0.8889\n",
      "Validation Acc: 0.4286, Validation F1: 0.5556\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, criterion, optimizer, train_loader, val_loader, epochs=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        total_loss = 0\n",
    "        train_preds, train_targets = [], []  # Initialize lists to store training predictions and targets\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Convert outputs to probabilities and then to binary predictions\n",
    "            preds = torch.sigmoid(outputs).data > 0.5\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Calculate and print training accuracy and F1 score\n",
    "        train_acc = accuracy_score(train_targets, np.round(train_preds))\n",
    "        train_f1 = f1_score(train_targets, np.round(train_preds))\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {total_loss / len(train_loader)}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}\")\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        val_preds, val_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = torch.sigmoid(model(images))\n",
    "                preds = (outputs > 0.5).int()\n",
    "                val_preds.extend(preds.view(-1).cpu().numpy())\n",
    "                val_targets.extend(labels.cpu().numpy())\n",
    "            \n",
    "            val_acc = accuracy_score(val_targets, val_preds)\n",
    "            val_f1 = f1_score(val_targets, val_preds)\n",
    "            print(f\"Validation Acc: {val_acc:.4f}, Validation F1: {val_f1:.4f}\")\n",
    "\n",
    "model2 = train_model(model, criterion, optimizer, train_loader, val_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'ViT.pth'\n",
    "torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test_Predictions_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_csv_path = r'C:\\Users\\Fatima Azfar\\Desktop\\AIC-2024\\Round 1\\Train.csv'\n",
    "df = pd.read_csv(labels_csv_path)\n",
    "\n",
    "image_files = df['Image'].values\n",
    "image_files = [f\"{name}.jpg\" for name in image_files]\n",
    "labels = df['Label'].values\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_dataset = CustomDataset(image_files, labels, r'C:\\Users\\Fatima Azfar\\Desktop\\AIC-2024\\Round 1\\Training Images', transform=transform)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.5619, Test F1: 0.6236\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    test_preds, test_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = torch.sigmoid(model(images))\n",
    "            preds = (outputs > 0.5).int()\n",
    "            test_preds.extend(preds.cpu().numpy())\n",
    "            test_targets.extend(labels.cpu().numpy())\n",
    "    \n",
    "    test_acc = accuracy_score(test_targets, test_preds)\n",
    "    test_f1 = f1_score(test_targets, test_preds)\n",
    "    print(f\"Test Acc: {test_acc:.4f}, Test F1: {test_f1:.4f}\")\n",
    "\n",
    "evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (20x100352 and 41472x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Assuming your model is named 'model2' and is already trained\u001b[39;00m\n\u001b[0;32m     28\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m predict_on_test_loader(model, test_loader, device)\n",
      "Cell \u001b[1;32mIn[97], line 20\u001b[0m, in \u001b[0;36mpredict_on_test_loader\u001b[1;34m(model, test_loader, device)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m     19\u001b[0m     images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Move images to the appropriate device\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m     21\u001b[0m     probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(outputs)  \u001b[38;5;66;03m# Convert logits to probabilities for binary classification\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     preds \u001b[38;5;241m=\u001b[39m (probs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mint()  \u001b[38;5;66;03m# Threshold probabilities to obtain binary predictions\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Fatima Azfar\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Fatima Azfar\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[81], line 56\u001b[0m, in \u001b[0;36mSimpleCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     54\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(x)\n\u001b[0;32m     55\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[1;32m---> 56\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n\u001b[0;32m     57\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Fatima Azfar\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Fatima Azfar\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Fatima Azfar\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (20x100352 and 41472x512)"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('Testing.csv')\n",
    "test_image_files = test_df['Image'].values\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "test_dataset = TestDataset(test_image_files, 'Testing Image', transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=20, shuffle=False)\n",
    "\n",
    "def predict_on_test_loader(model, test_loader, device):\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    test_preds = []  # Initialize a list to store predictions\n",
    "\n",
    "    with torch.no_grad():  # No need to compute gradients\n",
    "        for images in test_loader:\n",
    "            images = images.to(device)  # Move images to the appropriate device\n",
    "            outputs = model(images)\n",
    "            probs = torch.sigmoid(outputs)  # Convert logits to probabilities for binary classification\n",
    "            preds = (probs > 0.5).int()  # Threshold probabilities to obtain binary predictions\n",
    "            test_preds.extend(preds.cpu().numpy())  # Move predictions to CPU and convert to numpy\n",
    "\n",
    "    return np.array(test_preds).flatten()  # Flatten the list of predictions if necessary and return\n",
    "\n",
    "# Assuming your model is named 'model2' and is already trained\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "test_predictions = predict_on_test_loader(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping_inverse = {0: 'Normal', 1: 'Mitosis'}\n",
    "textual_predictions = [label_mapping_inverse[pred] for pred in test_predictions]\n",
    "test_df['Label'] = textual_predictions\n",
    "test_df.to_csv('Test_Predictions_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "- added k-fold cross validation\n",
    "- added more augmentation\n",
    "- added smote for synthetic images to deal with imbalance\n",
    "- added early dropout\n",
    "- added weight decay for L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "--------------------------------\n",
      "Epoch 1, Train Loss: 8.9847, Train Acc: 0.5000, Train F1: 0.5667, Val Loss: 3.0894, Val Acc: 0.5714, Val F1: 0.7273\n",
      "Epoch 2, Train Loss: 15.8683, Train Acc: 0.5962, Train F1: 0.7470, Val Loss: 1.4659, Val Acc: 0.4286, Val F1: 0.2000\n",
      "Epoch 3, Train Loss: 2.9730, Train Acc: 0.5769, Train F1: 0.5000, Val Loss: 2.8231, Val Acc: 0.4286, Val F1: 0.0000\n",
      "Epoch 4, Train Loss: 3.8953, Train Acc: 0.4231, Train F1: 0.2105, Val Loss: 2.2121, Val Acc: 0.5000, Val F1: 0.2222\n",
      "Epoch 5, Train Loss: 2.0703, Train Acc: 0.6538, Train F1: 0.6087, Val Loss: 1.3138, Val Acc: 0.7143, Val F1: 0.7143\n",
      "Epoch 6, Train Loss: 2.1033, Train Acc: 0.5769, Train F1: 0.5769, Val Loss: 2.5673, Val Acc: 0.5714, Val F1: 0.4000\n",
      "Epoch 7, Train Loss: 2.0596, Train Acc: 0.5962, Train F1: 0.5714, Val Loss: 1.8020, Val Acc: 0.7143, Val F1: 0.7143\n",
      "Epoch 8, Train Loss: 1.6903, Train Acc: 0.6346, Train F1: 0.6415, Val Loss: 0.7776, Val Acc: 0.7857, Val F1: 0.7692\n",
      "Epoch 9, Train Loss: 1.5152, Train Acc: 0.5577, Train F1: 0.5818, Val Loss: 0.3637, Val Acc: 0.7857, Val F1: 0.8000\n",
      "Epoch 10, Train Loss: 1.8595, Train Acc: 0.5577, Train F1: 0.5818, Val Loss: 1.1341, Val Acc: 0.7143, Val F1: 0.6667\n",
      "FOLD 1\n",
      "--------------------------------\n",
      "Epoch 1, Train Loss: 11.2077, Train Acc: 0.4906, Train F1: 0.5970, Val Loss: 1.8873, Val Acc: 0.4615, Val F1: 0.0000\n",
      "Epoch 2, Train Loss: 6.9527, Train Acc: 0.3962, Train F1: 0.0000, Val Loss: 0.8051, Val Acc: 0.3846, Val F1: 0.2000\n",
      "Epoch 3, Train Loss: 1.6155, Train Acc: 0.6415, Train F1: 0.7711, Val Loss: 1.3603, Val Acc: 0.5385, Val F1: 0.6667\n",
      "Epoch 4, Train Loss: 1.6940, Train Acc: 0.6604, Train F1: 0.7805, Val Loss: 1.0552, Val Acc: 0.5385, Val F1: 0.6667\n",
      "Epoch 5, Train Loss: 1.1244, Train Acc: 0.7358, Train F1: 0.8205, Val Loss: 1.0433, Val Acc: 0.6923, Val F1: 0.7500\n",
      "Epoch 6, Train Loss: 1.2784, Train Acc: 0.7170, Train F1: 0.8052, Val Loss: 1.6634, Val Acc: 0.5385, Val F1: 0.6667\n",
      "Epoch 7, Train Loss: 0.8013, Train Acc: 0.7170, Train F1: 0.8000, Val Loss: 0.9923, Val Acc: 0.6923, Val F1: 0.7500\n",
      "Epoch 8, Train Loss: 0.7862, Train Acc: 0.6981, Train F1: 0.7714, Val Loss: 0.9151, Val Acc: 0.6154, Val F1: 0.7059\n",
      "Epoch 9, Train Loss: 1.0628, Train Acc: 0.6792, Train F1: 0.7536, Val Loss: 0.6975, Val Acc: 0.6923, Val F1: 0.7778\n",
      "Epoch 10, Train Loss: 0.5219, Train Acc: 0.7547, Train F1: 0.8169, Val Loss: 1.4734, Val Acc: 0.6154, Val F1: 0.7059\n",
      "FOLD 2\n",
      "--------------------------------\n",
      "Epoch 1, Train Loss: 13.7899, Train Acc: 0.4528, Train F1: 0.5397, Val Loss: 2.9897, Val Acc: 0.6154, Val F1: 0.7619\n",
      "Epoch 2, Train Loss: 17.4425, Train Acc: 0.5849, Train F1: 0.7381, Val Loss: 0.7034, Val Acc: 0.4615, Val F1: 0.5333\n",
      "Epoch 3, Train Loss: 2.9573, Train Acc: 0.4528, Train F1: 0.4314, Val Loss: 2.0614, Val Acc: 0.3846, Val F1: 0.0000\n",
      "Epoch 4, Train Loss: 3.2966, Train Acc: 0.4151, Train F1: 0.0000, Val Loss: 2.5123, Val Acc: 0.3846, Val F1: 0.0000\n",
      "Epoch 5, Train Loss: 2.6740, Train Acc: 0.4151, Train F1: 0.0000, Val Loss: 1.6978, Val Acc: 0.3846, Val F1: 0.0000\n",
      "Epoch 6, Train Loss: 2.1466, Train Acc: 0.4151, Train F1: 0.0000, Val Loss: 1.5274, Val Acc: 0.4615, Val F1: 0.2222\n",
      "Epoch 7, Train Loss: 1.4393, Train Acc: 0.4340, Train F1: 0.0625, Val Loss: 1.3853, Val Acc: 0.4615, Val F1: 0.2222\n",
      "Epoch 8, Train Loss: 1.5247, Train Acc: 0.4528, Train F1: 0.1212, Val Loss: 1.6228, Val Acc: 0.3846, Val F1: 0.0000\n",
      "Epoch 9, Train Loss: 1.4265, Train Acc: 0.4528, Train F1: 0.1212, Val Loss: 1.4523, Val Acc: 0.3846, Val F1: 0.0000\n",
      "Epoch 10, Train Loss: 1.2741, Train Acc: 0.4340, Train F1: 0.1176, Val Loss: 1.1553, Val Acc: 0.4615, Val F1: 0.2222\n",
      "FOLD 3\n",
      "--------------------------------\n",
      "Epoch 1, Train Loss: 8.3239, Train Acc: 0.6038, Train F1: 0.5714, Val Loss: 2.9165, Val Acc: 0.6923, Val F1: 0.8182\n",
      "Epoch 2, Train Loss: 14.7544, Train Acc: 0.5660, Train F1: 0.7229, Val Loss: 0.9770, Val Acc: 0.3846, Val F1: 0.3333\n",
      "Epoch 3, Train Loss: 4.0256, Train Acc: 0.4528, Train F1: 0.3830, Val Loss: 3.9071, Val Acc: 0.3077, Val F1: 0.0000\n",
      "Epoch 4, Train Loss: 4.4865, Train Acc: 0.4340, Train F1: 0.0000, Val Loss: 4.2648, Val Acc: 0.3077, Val F1: 0.0000\n",
      "Epoch 5, Train Loss: 3.5823, Train Acc: 0.4340, Train F1: 0.0000, Val Loss: 3.5947, Val Acc: 0.3077, Val F1: 0.0000\n",
      "Epoch 6, Train Loss: 2.5011, Train Acc: 0.4340, Train F1: 0.0625, Val Loss: 2.2190, Val Acc: 0.3077, Val F1: 0.1818\n",
      "Epoch 7, Train Loss: 1.3720, Train Acc: 0.5849, Train F1: 0.4762, Val Loss: 1.6562, Val Acc: 0.4615, Val F1: 0.4615\n",
      "Epoch 8, Train Loss: 1.5810, Train Acc: 0.4906, Train F1: 0.3415, Val Loss: 1.4248, Val Acc: 0.3846, Val F1: 0.2000\n",
      "Epoch 9, Train Loss: 1.4759, Train Acc: 0.4906, Train F1: 0.3721, Val Loss: 1.8677, Val Acc: 0.3077, Val F1: 0.1818\n",
      "Epoch 10, Train Loss: 1.2814, Train Acc: 0.6038, Train F1: 0.5116, Val Loss: 1.2615, Val Acc: 0.6154, Val F1: 0.6154\n",
      "FOLD 4\n",
      "--------------------------------\n",
      "Epoch 1, Train Loss: 27.3083, Train Acc: 0.4906, Train F1: 0.6087, Val Loss: 1.3186, Val Acc: 0.5385, Val F1: 0.7000\n",
      "Epoch 2, Train Loss: 3.0955, Train Acc: 0.5660, Train F1: 0.5490, Val Loss: 1.2834, Val Acc: 0.4615, Val F1: 0.0000\n",
      "Epoch 3, Train Loss: 3.2420, Train Acc: 0.3962, Train F1: 0.0000, Val Loss: 0.8619, Val Acc: 0.4615, Val F1: 0.0000\n",
      "Epoch 4, Train Loss: 1.2241, Train Acc: 0.3962, Train F1: 0.0000, Val Loss: 0.8743, Val Acc: 0.4615, Val F1: 0.0000\n",
      "Epoch 5, Train Loss: 1.0354, Train Acc: 0.3962, Train F1: 0.0000, Val Loss: 0.8142, Val Acc: 0.4615, Val F1: 0.0000\n",
      "Epoch 6, Train Loss: 0.9042, Train Acc: 0.3962, Train F1: 0.0000, Val Loss: 0.7424, Val Acc: 0.4615, Val F1: 0.0000\n",
      "Epoch 7, Train Loss: 0.8175, Train Acc: 0.3962, Train F1: 0.0000, Val Loss: 0.7544, Val Acc: 0.4615, Val F1: 0.0000\n",
      "Epoch 8, Train Loss: 0.8087, Train Acc: 0.3962, Train F1: 0.0000, Val Loss: 0.7561, Val Acc: 0.4615, Val F1: 0.0000\n",
      "Epoch 9, Train Loss: 0.8051, Train Acc: 0.3962, Train F1: 0.0000, Val Loss: 0.7896, Val Acc: 0.4615, Val F1: 0.0000\n",
      "Epoch 10, Train Loss: 0.8251, Train Acc: 0.3962, Train F1: 0.0000, Val Loss: 0.7829, Val Acc: 0.4615, Val F1: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "labels_csv_path = 'Training.csv'\n",
    "df = pd.read_csv(labels_csv_path)\n",
    "\n",
    "image_files = df['Image'].values\n",
    "labels = df['Label'].values\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 18 * 18, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define transforms with augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.05, p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, device):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_losses, train_preds, train_targets = [], [], []\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "            preds = torch.sigmoid(outputs).data > 0.5\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(train_targets, np.round(train_preds))\n",
    "        train_f1 = f1_score(train_targets, np.round(train_preds))\n",
    "\n",
    "        model.eval()\n",
    "        val_losses, val_preds, val_targets = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_losses.append(loss.item())\n",
    "                preds = torch.sigmoid(outputs).data > 0.5\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_acc = accuracy_score(val_targets, val_preds)\n",
    "        val_f1 = f1_score(val_targets, val_preds)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}, Train Loss: {np.mean(train_losses):.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}, Val Loss: {np.mean(val_losses):.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 10\n",
    "batch_size = 20\n",
    "k_folds = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Dataset and DataLoader\n",
    "dataset = CustomDataset(image_files,labels,'Training Image',transform=transform)\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(dataset)):\n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "    \n",
    "    train_subsampler = SubsetRandomSampler(train_ids)\n",
    "    val_subsampler = SubsetRandomSampler(val_ids)\n",
    "\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_subsampler)\n",
    "    val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_subsampler)\n",
    "\n",
    "    model = SimpleCNN().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "    \n",
    "    # Train the model\n",
    "    train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 14.6676, Train Acc: 0.3846, Train F1: 0.5000, Val Loss: 17.1431, Val Acc: 0.3571, Val F1: 0.0000\n",
      "Epoch 2/20, Train Loss: 5.5237, Train Acc: 0.4808, Train F1: 0.5424, Val Loss: 5.0760, Val Acc: 0.6429, Val F1: 0.7059\n",
      "Epoch 3/20, Train Loss: 4.0492, Train Acc: 0.6923, Train F1: 0.7838, Val Loss: 2.1070, Val Acc: 0.5000, Val F1: 0.4615\n",
      "Epoch 4/20, Train Loss: 2.3772, Train Acc: 0.6346, Train F1: 0.6415, Val Loss: 2.5742, Val Acc: 0.4286, Val F1: 0.2000\n",
      "Epoch 5/20, Train Loss: 2.0530, Train Acc: 0.4808, Train F1: 0.4000, Val Loss: 1.9814, Val Acc: 0.7143, Val F1: 0.8000\n",
      "Epoch 6/20, Train Loss: 1.1037, Train Acc: 0.6731, Train F1: 0.7733, Val Loss: 1.7738, Val Acc: 0.5000, Val F1: 0.4615\n",
      "Epoch 7/20, Train Loss: 1.1419, Train Acc: 0.6538, Train F1: 0.6786, Val Loss: 1.7505, Val Acc: 0.4286, Val F1: 0.3333\n",
      "Epoch 8/20, Train Loss: 0.7680, Train Acc: 0.7308, Train F1: 0.7941, Val Loss: 0.3815, Val Acc: 0.5714, Val F1: 0.7000\n",
      "Epoch 9/20, Train Loss: 0.7323, Train Acc: 0.7885, Train F1: 0.8358, Val Loss: 0.6189, Val Acc: 0.5000, Val F1: 0.5333\n",
      "Epoch 10/20, Train Loss: 0.8367, Train Acc: 0.7115, Train F1: 0.7619, Val Loss: 1.0836, Val Acc: 0.2857, Val F1: 0.2857\n",
      "Epoch 11/20, Train Loss: 0.9935, Train Acc: 0.5962, Train F1: 0.5882, Val Loss: 0.9294, Val Acc: 0.4286, Val F1: 0.5000\n",
      "Epoch 12/20, Train Loss: 0.7615, Train Acc: 0.6346, Train F1: 0.6885, Val Loss: 0.4724, Val Acc: 0.5714, Val F1: 0.6667\n",
      "Epoch 13/20, Train Loss: 0.9731, Train Acc: 0.7115, Train F1: 0.7945, Val Loss: 1.3291, Val Acc: 0.6429, Val F1: 0.7619\n",
      "Epoch 14/20, Train Loss: 0.6061, Train Acc: 0.7500, Train F1: 0.8060, Val Loss: 0.5699, Val Acc: 0.5000, Val F1: 0.4615\n",
      "Epoch 15/20, Train Loss: 0.8096, Train Acc: 0.5385, Train F1: 0.4783, Val Loss: 0.7739, Val Acc: 0.6429, Val F1: 0.6667\n",
      "Epoch 16/20, Train Loss: 0.5928, Train Acc: 0.7885, Train F1: 0.8358, Val Loss: 0.8137, Val Acc: 0.7143, Val F1: 0.8182\n",
      "Epoch 17/20, Train Loss: 0.5012, Train Acc: 0.8269, Train F1: 0.8696, Val Loss: 0.1739, Val Acc: 0.6429, Val F1: 0.7368\n",
      "Epoch 18/20, Train Loss: 0.5064, Train Acc: 0.7885, Train F1: 0.8358, Val Loss: 0.6620, Val Acc: 0.5000, Val F1: 0.5333\n",
      "Epoch 19/20, Train Loss: 0.5624, Train Acc: 0.7500, Train F1: 0.7937, Val Loss: 0.5352, Val Acc: 0.5000, Val F1: 0.5333\n",
      "Epoch 20/20, Train Loss: 0.5209, Train Acc: 0.7500, Train F1: 0.7937, Val Loss: 0.3653, Val Acc: 0.4286, Val F1: 0.5000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class RandomVerticalFlip(object):\n",
    "    \"\"\"Randomly flip the image vertically.\"\"\"\n",
    "    def __call__(self, img):\n",
    "        if random.random() > 0.5:\n",
    "            return TF.vflip(img)\n",
    "        return img\n",
    "\n",
    "# Define transforms with augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05), scale=(0.95, 1.05)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.05, p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = CustomDataset(train_files, train_labels, 'Training Image', transform=transform)\n",
    "val_dataset = CustomDataset(val_files, val_labels, 'Training Image', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=20, shuffle=False)\n",
    "\n",
    "# Model architecture\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 18 * 18, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming binary classification\n",
    "labels_unique = np.unique(train_labels)\n",
    "class_weights = compute_class_weight('balanced', classes=labels_unique, y=train_labels)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights_tensor[1])\n",
    "\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_preds, train_targets = [], []\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "            preds = torch.sigmoid(outputs).data > 0.5\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(train_targets, train_preds)\n",
    "        train_f1 = f1_score(train_targets, train_preds)\n",
    "\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        val_preds, val_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                val_losses.append(loss.item())\n",
    "                \n",
    "                preds = torch.sigmoid(outputs).data > 0.5\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_targets.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_acc = accuracy_score(val_targets, val_preds)\n",
    "        val_f1 = f1_score(val_targets, val_preds)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {np.mean(train_losses):.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}, Val Loss: {np.mean(val_losses):.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}')\n",
    "\n",
    "model1 = train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test_Predictions_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images in test_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = (probs > 0.5).int()\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "    return np.array(predictions).flatten()\n",
    "\n",
    "test_predictions = predict(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping_inverse = {0: 'Normal', 1: 'Mitosis'}\n",
    "textual_predictions = [label_mapping_inverse[pred] for pred in test_predictions]\n",
    "test_df['Label'] = textual_predictions\n",
    "test_df.to_csv('Test_Predictions_7.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fatima Azfar\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Fatima Azfar\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\Fatima Azfar\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.7282, Train Acc: 0.6000, Train F1: 0.7189, Val Loss: 0.8487, Val Acc: 0.5000, Val F1: 0.4615\n",
      "Epoch 2, Train Loss: 0.5278, Train Acc: 0.6937, Train F1: 0.7184, Val Loss: 0.8141, Val Acc: 0.7143, Val F1: 0.8182\n",
      "Epoch 3, Train Loss: 0.5482, Train Acc: 0.7812, Train F1: 0.8250, Val Loss: 1.1309, Val Acc: 0.6429, Val F1: 0.7368\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch 4, Train Loss: 0.4395, Train Acc: 0.7906, Train F1: 0.8269, Val Loss: 1.0953, Val Acc: 0.5714, Val F1: 0.6667\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch 5, Train Loss: 0.4596, Train Acc: 0.8219, Train F1: 0.8571, Val Loss: 0.8795, Val Acc: 0.5714, Val F1: 0.6250\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch 6, Train Loss: 0.3512, Train Acc: 0.8063, Train F1: 0.8409, Val Loss: 2.1732, Val Acc: 0.5714, Val F1: 0.6667\n",
      "EarlyStopping counter: 4 out of 5\n",
      "Epoch 7, Train Loss: 0.3760, Train Acc: 0.7812, Train F1: 0.8124, Val Loss: 1.8346, Val Acc: 0.6429, Val F1: 0.7368\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import os\n",
    "\n",
    "# Define transforms with augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05), scale=(0.95, 1.05)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.05, p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(train_files, train_labels, 'Training Image', transform=transform)\n",
    "val_dataset = CustomDataset(val_files, val_labels, 'Training Image', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load a pretrained DenseNet model\n",
    "model = models.densenet121(pretrained=True)\n",
    "num_ftrs = model.classifier.in_features\n",
    "model.classifier = nn.Linear(num_ftrs, 1)  # Change the final layer for binary classification\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.counter = 0\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "\n",
    "# Define the early stopping instance\n",
    "early_stopping = EarlyStopping(patience=5, verbose=True)\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, device, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss, train_acc, train_f1 = 0, 0, 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device).unsqueeze(1)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            predictions = torch.sigmoid(outputs) > 0.5\n",
    "            train_acc += accuracy_score(labels.cpu(), predictions.cpu())\n",
    "            train_f1 += f1_score(labels.cpu(), predictions.cpu(), zero_division=1)\n",
    "        \n",
    "        # Calculate average losses\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_acc = train_acc / len(train_loader)\n",
    "        train_f1 = train_f1 / len(train_loader)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss, val_acc, val_f1 = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device).unsqueeze(1)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                predictions = torch.sigmoid(outputs) > 0.5\n",
    "                val_acc += accuracy_score(labels.cpu(), predictions.cpu())\n",
    "                val_f1 += f1_score(labels.cpu(), predictions.cpu(), zero_division=1)\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = val_acc / len(val_loader)\n",
    "        val_f1 = val_f1 / len(val_loader)\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}')\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "        early_stopping(val_loss, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, verbose=True)\n",
    "\n",
    "train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, device, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test_Predictions_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "def predict(model, test_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for inputs in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            predicted_labels = (probs > 0.5).int()\n",
    "            predictions.extend(predicted_labels.cpu().numpy())\n",
    "    return predictions\n",
    "\n",
    "predictions = predict(model, test_loader, device)\n",
    "\n",
    "predictions = np.array(predictions).flatten()\n",
    "\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping_inverse = {0: 'Normal', 1: 'Mitosis'}\n",
    "textual_predictions = [label_mapping_inverse[pred] for pred in predictions]\n",
    "test_df['Label'] = textual_predictions\n",
    "test_df.to_csv('Test_Predictions_8.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 10.2827, Train Acc: 0.4615, Train F1: 0.5000, Val Loss: 13.6732, Val Acc: 0.3571, Val F1: 0.0000\n",
      "Epoch 2/50, Train Loss: 1.9112, Train Acc: 0.7885, Train F1: 0.8254, Val Loss: 0.6401, Val Acc: 0.3571, Val F1: 0.0000\n",
      "Epoch 3/50, Train Loss: 2.5481, Train Acc: 0.7885, Train F1: 0.8358, Val Loss: 5.8899, Val Acc: 0.4286, Val F1: 0.3333\n",
      "Epoch 4/50, Train Loss: 1.8944, Train Acc: 0.6731, Train F1: 0.6792, Val Loss: 2.5677, Val Acc: 0.4286, Val F1: 0.3333\n",
      "Epoch 5/50, Train Loss: 0.6912, Train Acc: 0.8269, Train F1: 0.8525, Val Loss: 1.1937, Val Acc: 0.6429, Val F1: 0.7368\n",
      "Epoch 6/50, Train Loss: 1.2663, Train Acc: 0.7885, Train F1: 0.8406, Val Loss: 0.3622, Val Acc: 0.7143, Val F1: 0.7778\n",
      "Epoch 7/50, Train Loss: 0.9847, Train Acc: 0.7115, Train F1: 0.7458, Val Loss: 0.8222, Val Acc: 0.5714, Val F1: 0.6250\n",
      "Epoch 8/50, Train Loss: 1.0931, Train Acc: 0.8269, Train F1: 0.8364, Val Loss: 0.5637, Val Acc: 0.5714, Val F1: 0.6667\n",
      "Epoch 9/50, Train Loss: 0.9992, Train Acc: 0.8077, Train F1: 0.8438, Val Loss: 0.5827, Val Acc: 0.5714, Val F1: 0.6667\n",
      "Epoch 10/50, Train Loss: 0.6267, Train Acc: 0.8269, Train F1: 0.8615, Val Loss: 0.0254, Val Acc: 0.5000, Val F1: 0.5882\n",
      "Epoch 11/50, Train Loss: 0.3085, Train Acc: 0.8846, Train F1: 0.9091, Val Loss: 0.1023, Val Acc: 0.5000, Val F1: 0.5333\n",
      "Epoch 12/50, Train Loss: 0.4451, Train Acc: 0.8462, Train F1: 0.8519, Val Loss: 0.7265, Val Acc: 0.5714, Val F1: 0.6250\n",
      "Epoch 13/50, Train Loss: 0.3348, Train Acc: 0.9231, Train F1: 0.9355, Val Loss: 0.5397, Val Acc: 0.5714, Val F1: 0.6667\n",
      "Epoch 14/50, Train Loss: 0.8384, Train Acc: 0.8269, Train F1: 0.8696, Val Loss: 1.0467, Val Acc: 0.6429, Val F1: 0.7059\n",
      "Epoch 15/50, Train Loss: 0.4189, Train Acc: 0.8462, Train F1: 0.8571, Val Loss: 0.2861, Val Acc: 0.5714, Val F1: 0.6250\n",
      "Epoch 16/50, Train Loss: 0.5198, Train Acc: 0.8654, Train F1: 0.8814, Val Loss: 0.3482, Val Acc: 0.6429, Val F1: 0.7059\n",
      "Epoch 17/50, Train Loss: 0.3179, Train Acc: 0.9038, Train F1: 0.9231, Val Loss: 0.0319, Val Acc: 0.5714, Val F1: 0.6667\n",
      "Epoch 18/50, Train Loss: 0.1806, Train Acc: 0.9423, Train F1: 0.9508, Val Loss: 0.1482, Val Acc: 0.6429, Val F1: 0.7059\n",
      "Epoch 19/50, Train Loss: 0.5898, Train Acc: 0.8654, Train F1: 0.8852, Val Loss: 1.0792, Val Acc: 0.7143, Val F1: 0.7778\n",
      "Epoch 20/50, Train Loss: 0.1765, Train Acc: 0.9231, Train F1: 0.9286, Val Loss: 0.2751, Val Acc: 0.6429, Val F1: 0.7059\n",
      "Epoch 21/50, Train Loss: 0.1908, Train Acc: 0.9038, Train F1: 0.9180, Val Loss: 0.2923, Val Acc: 0.5714, Val F1: 0.6250\n",
      "Epoch 22/50, Train Loss: 0.2143, Train Acc: 0.9423, Train F1: 0.9508, Val Loss: 0.1126, Val Acc: 0.5714, Val F1: 0.6250\n",
      "Epoch 23/50, Train Loss: 0.2023, Train Acc: 0.8846, Train F1: 0.9032, Val Loss: 0.1329, Val Acc: 0.5000, Val F1: 0.5882\n",
      "Epoch 24/50, Train Loss: 0.0728, Train Acc: 1.0000, Train F1: 1.0000, Val Loss: 0.0262, Val Acc: 0.5714, Val F1: 0.5714\n",
      "Epoch 25/50, Train Loss: 0.1702, Train Acc: 0.9615, Train F1: 0.9655, Val Loss: 0.1762, Val Acc: 0.6429, Val F1: 0.6667\n",
      "Epoch 26/50, Train Loss: 0.1278, Train Acc: 0.9231, Train F1: 0.9375, Val Loss: 0.0239, Val Acc: 0.5714, Val F1: 0.6667\n",
      "Epoch 27/50, Train Loss: 0.1898, Train Acc: 0.9423, Train F1: 0.9524, Val Loss: 0.0739, Val Acc: 0.6429, Val F1: 0.7059\n",
      "Epoch 28/50, Train Loss: 0.1864, Train Acc: 0.9038, Train F1: 0.9180, Val Loss: 0.3905, Val Acc: 0.5000, Val F1: 0.5333\n",
      "Epoch 29/50, Train Loss: 0.2749, Train Acc: 0.9231, Train F1: 0.9286, Val Loss: 0.0637, Val Acc: 0.7143, Val F1: 0.7778\n",
      "Epoch 30/50, Train Loss: 0.1825, Train Acc: 0.9231, Train F1: 0.9375, Val Loss: 0.1632, Val Acc: 0.6429, Val F1: 0.7059\n",
      "Epoch 31/50, Train Loss: 0.4335, Train Acc: 0.9231, Train F1: 0.9375, Val Loss: 0.9012, Val Acc: 0.6429, Val F1: 0.7059\n",
      "Epoch 32/50, Train Loss: 0.3819, Train Acc: 0.8269, Train F1: 0.8364, Val Loss: 0.1756, Val Acc: 0.5714, Val F1: 0.6250\n",
      "Epoch 33/50, Train Loss: 0.2764, Train Acc: 0.8846, Train F1: 0.8889, Val Loss: 0.2728, Val Acc: 0.6429, Val F1: 0.7368\n",
      "Epoch 34/50, Train Loss: 0.2395, Train Acc: 0.8846, Train F1: 0.9091, Val Loss: 0.0016, Val Acc: 0.5714, Val F1: 0.6667\n",
      "Epoch 35/50, Train Loss: 0.1297, Train Acc: 0.9231, Train F1: 0.9375, Val Loss: 0.0365, Val Acc: 0.5714, Val F1: 0.6667\n",
      "Epoch 36/50, Train Loss: 0.0777, Train Acc: 0.9808, Train F1: 0.9836, Val Loss: 0.0163, Val Acc: 0.6429, Val F1: 0.7059\n",
      "Epoch 37/50, Train Loss: 0.4069, Train Acc: 0.9038, Train F1: 0.9091, Val Loss: 1.0162, Val Acc: 0.6429, Val F1: 0.7059\n",
      "Epoch 38/50, Train Loss: 0.0458, Train Acc: 1.0000, Train F1: 1.0000, Val Loss: 0.0665, Val Acc: 0.6429, Val F1: 0.7059\n",
      "Epoch 39/50, Train Loss: 0.5666, Train Acc: 0.8654, Train F1: 0.8923, Val Loss: 0.2425, Val Acc: 0.6429, Val F1: 0.7059\n",
      "Epoch 40/50, Train Loss: 0.4625, Train Acc: 0.9231, Train F1: 0.9375, Val Loss: 0.7809, Val Acc: 0.6429, Val F1: 0.7059\n",
      "Epoch 41/50, Train Loss: 0.2857, Train Acc: 0.9423, Train F1: 0.9524, Val Loss: 0.5831, Val Acc: 0.4286, Val F1: 0.4286\n",
      "Epoch 42/50, Train Loss: 0.4628, Train Acc: 0.8654, Train F1: 0.8679, Val Loss: 0.4532, Val Acc: 0.5714, Val F1: 0.6250\n",
      "Epoch 43/50, Train Loss: 0.2145, Train Acc: 0.9231, Train F1: 0.9310, Val Loss: 0.0314, Val Acc: 0.6429, Val F1: 0.7059\n",
      "Epoch 44/50, Train Loss: 0.5346, Train Acc: 0.8846, Train F1: 0.9091, Val Loss: 0.0121, Val Acc: 0.5714, Val F1: 0.6250\n",
      "Epoch 45/50, Train Loss: 0.1270, Train Acc: 0.9615, Train F1: 0.9667, Val Loss: 0.0793, Val Acc: 0.5000, Val F1: 0.5333\n",
      "Epoch 46/50, Train Loss: 0.0198, Train Acc: 1.0000, Train F1: 1.0000, Val Loss: 0.0265, Val Acc: 0.4286, Val F1: 0.4286\n",
      "Epoch 47/50, Train Loss: 0.2199, Train Acc: 0.9615, Train F1: 0.9667, Val Loss: 0.0895, Val Acc: 0.5714, Val F1: 0.5714\n",
      "Epoch 48/50, Train Loss: 0.0681, Train Acc: 0.9808, Train F1: 0.9831, Val Loss: 0.0704, Val Acc: 0.5000, Val F1: 0.5333\n",
      "Epoch 49/50, Train Loss: 0.4128, Train Acc: 0.9231, Train F1: 0.9333, Val Loss: 1.1060, Val Acc: 0.5714, Val F1: 0.6250\n",
      "Epoch 50/50, Train Loss: 0.2880, Train Acc: 0.8846, Train F1: 0.8929, Val Loss: 0.6750, Val Acc: 0.5714, Val F1: 0.6250\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Define transforms with augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = CustomDataset(train_files, train_labels, 'Training Image', transform=transform)\n",
    "val_dataset = CustomDataset(val_files, val_labels, 'Training Image', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=20, shuffle=False)\n",
    "\n",
    "# Model architecture\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 18 * 18, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming binary classification\n",
    "labels_unique = np.unique(train_labels)\n",
    "class_weights = compute_class_weight('balanced', classes=labels_unique, y=train_labels)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights_tensor[1])\n",
    "\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_preds, train_targets = [], []\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "            \n",
    "            preds = torch.sigmoid(outputs).data > 0.5\n",
    "            train_preds.extend(preds.cpu().numpy())\n",
    "            train_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(train_targets, train_preds)\n",
    "        train_f1 = f1_score(train_targets, train_preds)\n",
    "\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        val_preds, val_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                val_losses.append(loss.item())\n",
    "                \n",
    "                preds = torch.sigmoid(outputs).data > 0.5\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_targets.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_acc = accuracy_score(val_targets, val_preds)\n",
    "        val_f1 = f1_score(val_targets, val_preds)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {np.mean(train_losses):.4f}, Train Acc: {train_acc:.4f}, Train F1: {train_f1:.4f}, Val Loss: {np.mean(val_losses):.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}')\n",
    "\n",
    "model1 = train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
